{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 tweet = document\n",
    "\n",
    "1) lower case\n",
    "\n",
    "2) remove stopwords\n",
    "\n",
    "3) remove stems and lemmas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem import LancasterStemmer, SnowballStemmer, RegexpStemmer, WordNetLemmatizer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DataFrame and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleaned_all_samples.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243390\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>label</th>\n",
       "      <th>like_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>tweet</th>\n",
       "      <th>cleaned_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[politics]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#politics NH gun shop owner gifts Trump semi-a...</td>\n",
       "      <td>NH gun shop owner gifts Trump semi-automatic r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[ISIS, targets, iceisis, opiceisis]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RT @CtrlSec: Targeted #ISIS accounts https://t...</td>\n",
       "      <td>Targeted  accounts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16-year-old environmental activist Greta Thunb...</td>\n",
       "      <td>16-year-old environmental activist Greta Thunb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>['#moleg']</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Thank God for @repdottieb4mo  Under her watch,...</td>\n",
       "      <td>Thank God for   Under her watch,  110 remains ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The Rise of Purpose Education: A Recipe for Fu...</td>\n",
       "      <td>The Rise of Purpose Education: A Recipe for Fu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                             hashtags  label  like_count  \\\n",
       "0           0                           [politics]      1         0.0   \n",
       "1           1  [ISIS, targets, iceisis, opiceisis]      1         0.0   \n",
       "2           2                                   []      0        42.0   \n",
       "3           3                           ['#moleg']      0         6.0   \n",
       "4           4                                   []      0         4.0   \n",
       "\n",
       "   reply_count  retweet_count  \\\n",
       "0          0.0            0.0   \n",
       "1          0.0            0.0   \n",
       "2          0.0            9.0   \n",
       "3          1.0            1.0   \n",
       "4          0.0            0.0   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  #politics NH gun shop owner gifts Trump semi-a...   \n",
       "1  RT @CtrlSec: Targeted #ISIS accounts https://t...   \n",
       "2  16-year-old environmental activist Greta Thunb...   \n",
       "3  Thank God for @repdottieb4mo  Under her watch,...   \n",
       "4  The Rise of Purpose Education: A Recipe for Fu...   \n",
       "\n",
       "                                      cleaned_tweets  \n",
       "0  NH gun shop owner gifts Trump semi-automatic r...  \n",
       "1                                 Targeted  accounts  \n",
       "2  16-year-old environmental activist Greta Thunb...  \n",
       "3  Thank God for   Under her watch,  110 remains ...  \n",
       "4  The Rise of Purpose Education: A Recipe for Fu...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sentence tokenizer\n",
    "from nltk import sent_tokenize\n",
    "\n",
    "#import word tokenizer\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/markbrennan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this was part of the NLP notebook\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0            0\n",
       "hashtags          10770\n",
       "label                 0\n",
       "like_count           96\n",
       "reply_count          96\n",
       "retweet_count        96\n",
       "tweet                 0\n",
       "cleaned_tweets       74\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#eda to check for na's\n",
    "\n",
    "df.isnull().sum()\n",
    "\n",
    "#NOTE: some tweets became NaN's after they were cleaned, probably insignificant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the NaN's from cleaned_tweets\n",
    "\n",
    "df['cleaned_tweets'].dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0            0\n",
       "hashtags          10770\n",
       "label                 0\n",
       "like_count           96\n",
       "reply_count          96\n",
       "retweet_count        96\n",
       "tweet                 0\n",
       "cleaned_tweets       74\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum() # checking NaN's again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lowercase and Tokenize the Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lowercase all the values in the cleaned tweets\n",
    "\n",
    "df['cleaned_tweets'] = df.cleaned_tweets.astype(str).str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize all rows of cleaned tweets\n",
    "\n",
    "df['tokenized_tweets'] = df['cleaned_tweets'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>label</th>\n",
       "      <th>like_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>tweet</th>\n",
       "      <th>cleaned_tweets</th>\n",
       "      <th>tokenized_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[politics]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#politics NH gun shop owner gifts Trump semi-a...</td>\n",
       "      <td>nh gun shop owner gifts trump semi-automatic r...</td>\n",
       "      <td>[nh, gun, shop, owner, gifts, trump, semi-auto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[ISIS, targets, iceisis, opiceisis]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RT @CtrlSec: Targeted #ISIS accounts https://t...</td>\n",
       "      <td>targeted  accounts</td>\n",
       "      <td>[targeted, accounts]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16-year-old environmental activist Greta Thunb...</td>\n",
       "      <td>16-year-old environmental activist greta thunb...</td>\n",
       "      <td>[16-year-old, environmental, activist, greta, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>['#moleg']</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Thank God for @repdottieb4mo  Under her watch,...</td>\n",
       "      <td>thank god for   under her watch,  110 remains ...</td>\n",
       "      <td>[thank, god, for, under, her, watch, ,, 110, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The Rise of Purpose Education: A Recipe for Fu...</td>\n",
       "      <td>the rise of purpose education: a recipe for fu...</td>\n",
       "      <td>[the, rise, of, purpose, education, :, a, reci...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                             hashtags  label  like_count  \\\n",
       "0           0                           [politics]      1         0.0   \n",
       "1           1  [ISIS, targets, iceisis, opiceisis]      1         0.0   \n",
       "2           2                                   []      0        42.0   \n",
       "3           3                           ['#moleg']      0         6.0   \n",
       "4           4                                   []      0         4.0   \n",
       "\n",
       "   reply_count  retweet_count  \\\n",
       "0          0.0            0.0   \n",
       "1          0.0            0.0   \n",
       "2          0.0            9.0   \n",
       "3          1.0            1.0   \n",
       "4          0.0            0.0   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  #politics NH gun shop owner gifts Trump semi-a...   \n",
       "1  RT @CtrlSec: Targeted #ISIS accounts https://t...   \n",
       "2  16-year-old environmental activist Greta Thunb...   \n",
       "3  Thank God for @repdottieb4mo  Under her watch,...   \n",
       "4  The Rise of Purpose Education: A Recipe for Fu...   \n",
       "\n",
       "                                      cleaned_tweets  \\\n",
       "0  nh gun shop owner gifts trump semi-automatic r...   \n",
       "1                                 targeted  accounts   \n",
       "2  16-year-old environmental activist greta thunb...   \n",
       "3  thank god for   under her watch,  110 remains ...   \n",
       "4  the rise of purpose education: a recipe for fu...   \n",
       "\n",
       "                                    tokenized_tweets  \n",
       "0  [nh, gun, shop, owner, gifts, trump, semi-auto...  \n",
       "1                               [targeted, accounts]  \n",
       "2  [16-year-old, environmental, activist, greta, ...  \n",
       "3  [thank, god, for, under, her, watch, ,, 110, r...  \n",
       "4  [the, rise, of, purpose, education, :, a, reci...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_stopwords = set(stopwords.words('english'))\n",
    "# my_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stop words\n",
    "\n",
    "df['tokenized_tweets'] = df['tokenized_tweets'].apply(lambda x: [item for item in x if item not in my_stopwords])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing for stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t-minus 5 days until nyc!'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cleaned_tweets'][28] # checking for stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t-minus', '5', 'days', 'nyc', '!']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokenized_tweets'][28] # checking for stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct =[]\n",
    "punct += list(string.punctuation)\n",
    "punct += 'â€™'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~',\n",
       " 'â€™']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#borrowed code from StackOverFlow\n",
    "\n",
    "df['tokenized_tweets'] = df['tokenized_tweets'].apply(lambda x: [item for item in x if item not in punct])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare the cleaned / tokenized columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Itâ€™s something thatâ€™s been sticking out and definitely bothering me! Thereâ€™s the narrative that weâ€™re so liberal but 2018 was basically all moderates winning. And then of course the decision as to whatâ€™s a sexy storyline and what isnâ€™t. Think votes are what count ðŸ¤”'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet'][10] #comparing token cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'itâ€™s something thatâ€™s been sticking out and definitely bothering me! thereâ€™s the narrative that weâ€™re so liberal but 2018 was basically all moderates winning. and then of course the decision as to whatâ€™s a sexy storyline and what isnâ€™t. think votes are what count '"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cleaned_tweets'][10] #comparing token cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['something',\n",
       " 'sticking',\n",
       " 'definitely',\n",
       " 'bothering',\n",
       " 'narrative',\n",
       " 'liberal',\n",
       " '2018',\n",
       " 'basically',\n",
       " 'moderates',\n",
       " 'winning',\n",
       " 'course',\n",
       " 'decision',\n",
       " 'sexy',\n",
       " 'storyline',\n",
       " 'think',\n",
       " 'votes',\n",
       " 'count']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokenized_tweets'][10] #comparing token cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the tokens back to a string for stems and lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[dummy] is a dummy column to perform stem and lemma on\n",
    "\n",
    "df['dummy'] = df['tokenized_tweets'].apply(lambda x: ' '.join(map(str, x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>label</th>\n",
       "      <th>like_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>tweet</th>\n",
       "      <th>cleaned_tweets</th>\n",
       "      <th>tokenized_tweets</th>\n",
       "      <th>dummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[politics]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#politics NH gun shop owner gifts Trump semi-a...</td>\n",
       "      <td>nh gun shop owner gifts trump semi-automatic r...</td>\n",
       "      <td>[nh, gun, shop, owner, gifts, trump, semi-auto...</td>\n",
       "      <td>nh gun shop owner gifts trump semi-automatic r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[ISIS, targets, iceisis, opiceisis]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RT @CtrlSec: Targeted #ISIS accounts https://t...</td>\n",
       "      <td>targeted  accounts</td>\n",
       "      <td>[targeted, accounts]</td>\n",
       "      <td>targeted accounts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16-year-old environmental activist Greta Thunb...</td>\n",
       "      <td>16-year-old environmental activist greta thunb...</td>\n",
       "      <td>[16-year-old, environmental, activist, greta, ...</td>\n",
       "      <td>16-year-old environmental activist greta thunb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>['#moleg']</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Thank God for @repdottieb4mo  Under her watch,...</td>\n",
       "      <td>thank god for   under her watch,  110 remains ...</td>\n",
       "      <td>[thank, god, watch, 110, remains, safe, secure...</td>\n",
       "      <td>thank god watch 110 remains safe secure leftis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The Rise of Purpose Education: A Recipe for Fu...</td>\n",
       "      <td>the rise of purpose education: a recipe for fu...</td>\n",
       "      <td>[rise, purpose, education, recipe, fulfillment...</td>\n",
       "      <td>rise purpose education recipe fulfillment snow...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                             hashtags  label  like_count  \\\n",
       "0           0                           [politics]      1         0.0   \n",
       "1           1  [ISIS, targets, iceisis, opiceisis]      1         0.0   \n",
       "2           2                                   []      0        42.0   \n",
       "3           3                           ['#moleg']      0         6.0   \n",
       "4           4                                   []      0         4.0   \n",
       "\n",
       "   reply_count  retweet_count  \\\n",
       "0          0.0            0.0   \n",
       "1          0.0            0.0   \n",
       "2          0.0            9.0   \n",
       "3          1.0            1.0   \n",
       "4          0.0            0.0   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  #politics NH gun shop owner gifts Trump semi-a...   \n",
       "1  RT @CtrlSec: Targeted #ISIS accounts https://t...   \n",
       "2  16-year-old environmental activist Greta Thunb...   \n",
       "3  Thank God for @repdottieb4mo  Under her watch,...   \n",
       "4  The Rise of Purpose Education: A Recipe for Fu...   \n",
       "\n",
       "                                      cleaned_tweets  \\\n",
       "0  nh gun shop owner gifts trump semi-automatic r...   \n",
       "1                                 targeted  accounts   \n",
       "2  16-year-old environmental activist greta thunb...   \n",
       "3  thank god for   under her watch,  110 remains ...   \n",
       "4  the rise of purpose education: a recipe for fu...   \n",
       "\n",
       "                                    tokenized_tweets  \\\n",
       "0  [nh, gun, shop, owner, gifts, trump, semi-auto...   \n",
       "1                               [targeted, accounts]   \n",
       "2  [16-year-old, environmental, activist, greta, ...   \n",
       "3  [thank, god, watch, 110, remains, safe, secure...   \n",
       "4  [rise, purpose, education, recipe, fulfillment...   \n",
       "\n",
       "                                               dummy  \n",
       "0  nh gun shop owner gifts trump semi-automatic r...  \n",
       "1                                  targeted accounts  \n",
       "2  16-year-old environmental activist greta thunb...  \n",
       "3  thank god watch 110 remains safe secure leftis...  \n",
       "4  rise purpose education recipe fulfillment snow...  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() # checking results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stems and Lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import stemmers and lemmatizers\n",
    "\n",
    "from nltk.stem import LancasterStemmer, SnowballStemmer, RegexpStemmer, WordNetLemmatizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiating\n",
    "\n",
    "snowball = SnowballStemmer('english')\n",
    "lancaster = LancasterStemmer() #more aggressive\n",
    "regex_stemmer = RegexpStemmer('ing$|s$|e$|able$', min=4)\n",
    "lemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to get stems and lemmas\n",
    "\n",
    "def stem_words(document,stemmer):\n",
    "    # tokenize the text\n",
    "    toks = word_tokenize(document)\n",
    "    wrd_list = []\n",
    "    # go through the tokens\n",
    "    for word in toks:\n",
    "        # stem the tokens\n",
    "        wrd_list.append(stemmer.stem(word))\n",
    "    # return them\n",
    "    return \" \".join(wrd_list)\n",
    "\n",
    "\n",
    "def lem_words(document,lemmer):\n",
    "    toks = word_tokenize(document)\n",
    "    wrd_list = []\n",
    "    for word in toks:\n",
    "        wrd_list.append(lemmer.lemmatize(word))\n",
    "    return \" \".join(wrd_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['something',\n",
       " 'sticking',\n",
       " 'definitely',\n",
       " 'bothering',\n",
       " 'narrative',\n",
       " 'liberal',\n",
       " '2018',\n",
       " 'basically',\n",
       " 'moderates',\n",
       " 'winning',\n",
       " 'course',\n",
       " 'decision',\n",
       " 'sexy',\n",
       " 'storyline',\n",
       " 'think',\n",
       " 'votes',\n",
       " 'count']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokenized_tweets'][10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### combine tokens into a string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing a randomy dummy row to see how each stemmer/lemmer performs\n",
    "dummy = ' '.join(df['tokenized_tweets'][10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'someth stick definit bother narrat liber 2018 basic moder win cours decis sexi storylin think vote count'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_words(dummy, snowball)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'someth stick definit both nar lib 2018 bas mod win cours decid sexy storylin think vot count'"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_words(dummy, lancaster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'someth stick definitely bother narrativ liberal 2018 basically moderate winn cours decision sexy storylin think vote count'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_words(dummy, regex_stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'something sticking definitely bothering narrative liberal 2018 basically moderate winning course decision sexy storyline think vote count'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lem_words(dummy, lemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just testing stuff out now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'friend'"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma.lemmatize('friends')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['something',\n",
       " 'sticking',\n",
       " 'definitely',\n",
       " 'bothering',\n",
       " 'narrative',\n",
       " 'liberal',\n",
       " '2018',\n",
       " 'basically',\n",
       " 'moderates',\n",
       " 'winning',\n",
       " 'course',\n",
       " 'decision',\n",
       " 'sexy',\n",
       " 'storyline',\n",
       " 'think',\n",
       " 'votes',\n",
       " 'count']"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokenized_tweets'][10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 tweet = document\n",
    "\n",
    "1) lower case\n",
    "\n",
    "2) remove stopwords\n",
    "\n",
    "3) remove stems and lemmas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem import LancasterStemmer, SnowballStemmer, RegexpStemmer, WordNetLemmatizer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DataFrame and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleaned_all_samples.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243390\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>label</th>\n",
       "      <th>like_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>tweet</th>\n",
       "      <th>cleaned_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[politics]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#politics NH gun shop owner gifts Trump semi-a...</td>\n",
       "      <td>NH gun shop owner gifts Trump semi-automatic r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[ISIS, targets, iceisis, opiceisis]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RT @CtrlSec: Targeted #ISIS accounts https://t...</td>\n",
       "      <td>Targeted  accounts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16-year-old environmental activist Greta Thunb...</td>\n",
       "      <td>16-year-old environmental activist Greta Thunb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>['#moleg']</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Thank God for @repdottieb4mo  Under her watch,...</td>\n",
       "      <td>Thank God for   Under her watch,  110 remains ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The Rise of Purpose Education: A Recipe for Fu...</td>\n",
       "      <td>The Rise of Purpose Education: A Recipe for Fu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                             hashtags  label  like_count  \\\n",
       "0           0                           [politics]      1         0.0   \n",
       "1           1  [ISIS, targets, iceisis, opiceisis]      1         0.0   \n",
       "2           2                                   []      0        42.0   \n",
       "3           3                           ['#moleg']      0         6.0   \n",
       "4           4                                   []      0         4.0   \n",
       "\n",
       "   reply_count  retweet_count  \\\n",
       "0          0.0            0.0   \n",
       "1          0.0            0.0   \n",
       "2          0.0            9.0   \n",
       "3          1.0            1.0   \n",
       "4          0.0            0.0   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  #politics NH gun shop owner gifts Trump semi-a...   \n",
       "1  RT @CtrlSec: Targeted #ISIS accounts https://t...   \n",
       "2  16-year-old environmental activist Greta Thunb...   \n",
       "3  Thank God for @repdottieb4mo  Under her watch,...   \n",
       "4  The Rise of Purpose Education: A Recipe for Fu...   \n",
       "\n",
       "                                      cleaned_tweets  \n",
       "0  NH gun shop owner gifts Trump semi-automatic r...  \n",
       "1                                 Targeted  accounts  \n",
       "2  16-year-old environmental activist Greta Thunb...  \n",
       "3  Thank God for   Under her watch,  110 remains ...  \n",
       "4  The Rise of Purpose Education: A Recipe for Fu...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sentence tokenizer\n",
    "from nltk import sent_tokenize\n",
    "\n",
    "#import word tokenizer\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/markbrennan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this was part of the NLP notebook\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0            0\n",
       "hashtags          10770\n",
       "label                 0\n",
       "like_count           96\n",
       "reply_count          96\n",
       "retweet_count        96\n",
       "tweet                 0\n",
       "cleaned_tweets       74\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#eda to check for na's\n",
    "\n",
    "df.isnull().sum()\n",
    "\n",
    "#NOTE: some tweets became NaN's after they were cleaned, probably insignificant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the NaN's from cleaned_tweets\n",
    "\n",
    "df['cleaned_tweets'].dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0            0\n",
       "hashtags          10770\n",
       "label                 0\n",
       "like_count           96\n",
       "reply_count          96\n",
       "retweet_count        96\n",
       "tweet                 0\n",
       "cleaned_tweets       74\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum() # checking NaN's again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lowercase and Tokenize the Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lowercase all the values in the cleaned tweets\n",
    "\n",
    "df['cleaned_tweets'] = df.cleaned_tweets.astype(str).str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize all rows of cleaned tweets\n",
    "\n",
    "df['tokenized_tweets'] = df['cleaned_tweets'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>label</th>\n",
       "      <th>like_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>tweet</th>\n",
       "      <th>cleaned_tweets</th>\n",
       "      <th>tokenized_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[politics]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#politics NH gun shop owner gifts Trump semi-a...</td>\n",
       "      <td>nh gun shop owner gifts trump semi-automatic r...</td>\n",
       "      <td>[nh, gun, shop, owner, gifts, trump, semi-auto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[ISIS, targets, iceisis, opiceisis]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RT @CtrlSec: Targeted #ISIS accounts https://t...</td>\n",
       "      <td>targeted  accounts</td>\n",
       "      <td>[targeted, accounts]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16-year-old environmental activist Greta Thunb...</td>\n",
       "      <td>16-year-old environmental activist greta thunb...</td>\n",
       "      <td>[16-year-old, environmental, activist, greta, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>['#moleg']</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Thank God for @repdottieb4mo  Under her watch,...</td>\n",
       "      <td>thank god for   under her watch,  110 remains ...</td>\n",
       "      <td>[thank, god, for, under, her, watch, ,, 110, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The Rise of Purpose Education: A Recipe for Fu...</td>\n",
       "      <td>the rise of purpose education: a recipe for fu...</td>\n",
       "      <td>[the, rise, of, purpose, education, :, a, reci...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                             hashtags  label  like_count  \\\n",
       "0           0                           [politics]      1         0.0   \n",
       "1           1  [ISIS, targets, iceisis, opiceisis]      1         0.0   \n",
       "2           2                                   []      0        42.0   \n",
       "3           3                           ['#moleg']      0         6.0   \n",
       "4           4                                   []      0         4.0   \n",
       "\n",
       "   reply_count  retweet_count  \\\n",
       "0          0.0            0.0   \n",
       "1          0.0            0.0   \n",
       "2          0.0            9.0   \n",
       "3          1.0            1.0   \n",
       "4          0.0            0.0   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  #politics NH gun shop owner gifts Trump semi-a...   \n",
       "1  RT @CtrlSec: Targeted #ISIS accounts https://t...   \n",
       "2  16-year-old environmental activist Greta Thunb...   \n",
       "3  Thank God for @repdottieb4mo  Under her watch,...   \n",
       "4  The Rise of Purpose Education: A Recipe for Fu...   \n",
       "\n",
       "                                      cleaned_tweets  \\\n",
       "0  nh gun shop owner gifts trump semi-automatic r...   \n",
       "1                                 targeted  accounts   \n",
       "2  16-year-old environmental activist greta thunb...   \n",
       "3  thank god for   under her watch,  110 remains ...   \n",
       "4  the rise of purpose education: a recipe for fu...   \n",
       "\n",
       "                                    tokenized_tweets  \n",
       "0  [nh, gun, shop, owner, gifts, trump, semi-auto...  \n",
       "1                               [targeted, accounts]  \n",
       "2  [16-year-old, environmental, activist, greta, ...  \n",
       "3  [thank, god, for, under, her, watch, ,, 110, r...  \n",
       "4  [the, rise, of, purpose, education, :, a, reci...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_stopwords = set(stopwords.words('english'))\n",
    "# my_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stop words\n",
    "\n",
    "df['tokenized_tweets'] = df['tokenized_tweets'].apply(lambda x: [item for item in x if item not in my_stopwords])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing for stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t-minus 5 days until nyc!'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cleaned_tweets'][28] # checking for stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t-minus', '5', 'days', 'nyc', '!']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokenized_tweets'][28] # checking for stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct =[]\n",
    "punct += list(string.punctuation)\n",
    "punct += '’'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~',\n",
       " '’']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#borrowed code from StackOverFlow\n",
    "\n",
    "df['tokenized_tweets'] = df['tokenized_tweets'].apply(lambda x: [item for item in x if item not in punct])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare the cleaned / tokenized columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It’s something that’s been sticking out and definitely bothering me! There’s the narrative that we’re so liberal but 2018 was basically all moderates winning. And then of course the decision as to what’s a sexy storyline and what isn’t. Think votes are what count 🤔'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet'][10] #comparing token cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'it’s something that’s been sticking out and definitely bothering me! there’s the narrative that we’re so liberal but 2018 was basically all moderates winning. and then of course the decision as to what’s a sexy storyline and what isn’t. think votes are what count '"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cleaned_tweets'][10] #comparing token cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['something',\n",
       " 'sticking',\n",
       " 'definitely',\n",
       " 'bothering',\n",
       " 'narrative',\n",
       " 'liberal',\n",
       " '2018',\n",
       " 'basically',\n",
       " 'moderates',\n",
       " 'winning',\n",
       " 'course',\n",
       " 'decision',\n",
       " 'sexy',\n",
       " 'storyline',\n",
       " 'think',\n",
       " 'votes',\n",
       " 'count']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokenized_tweets'][10] #comparing token cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the tokens back to a string for stems and lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[dummy] is a dummy column to perform stem and lemma on\n",
    "\n",
    "df['dummy'] = df['tokenized_tweets'].apply(lambda x: ' '.join(map(str, x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>label</th>\n",
       "      <th>like_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>tweet</th>\n",
       "      <th>cleaned_tweets</th>\n",
       "      <th>tokenized_tweets</th>\n",
       "      <th>dummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[politics]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#politics NH gun shop owner gifts Trump semi-a...</td>\n",
       "      <td>nh gun shop owner gifts trump semi-automatic r...</td>\n",
       "      <td>[nh, gun, shop, owner, gifts, trump, semi-auto...</td>\n",
       "      <td>nh gun shop owner gifts trump semi-automatic r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[ISIS, targets, iceisis, opiceisis]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RT @CtrlSec: Targeted #ISIS accounts https://t...</td>\n",
       "      <td>targeted  accounts</td>\n",
       "      <td>[targeted, accounts]</td>\n",
       "      <td>targeted accounts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16-year-old environmental activist Greta Thunb...</td>\n",
       "      <td>16-year-old environmental activist greta thunb...</td>\n",
       "      <td>[16-year-old, environmental, activist, greta, ...</td>\n",
       "      <td>16-year-old environmental activist greta thunb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>['#moleg']</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Thank God for @repdottieb4mo  Under her watch,...</td>\n",
       "      <td>thank god for   under her watch,  110 remains ...</td>\n",
       "      <td>[thank, god, watch, 110, remains, safe, secure...</td>\n",
       "      <td>thank god watch 110 remains safe secure leftis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The Rise of Purpose Education: A Recipe for Fu...</td>\n",
       "      <td>the rise of purpose education: a recipe for fu...</td>\n",
       "      <td>[rise, purpose, education, recipe, fulfillment...</td>\n",
       "      <td>rise purpose education recipe fulfillment snow...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                             hashtags  label  like_count  \\\n",
       "0           0                           [politics]      1         0.0   \n",
       "1           1  [ISIS, targets, iceisis, opiceisis]      1         0.0   \n",
       "2           2                                   []      0        42.0   \n",
       "3           3                           ['#moleg']      0         6.0   \n",
       "4           4                                   []      0         4.0   \n",
       "\n",
       "   reply_count  retweet_count  \\\n",
       "0          0.0            0.0   \n",
       "1          0.0            0.0   \n",
       "2          0.0            9.0   \n",
       "3          1.0            1.0   \n",
       "4          0.0            0.0   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  #politics NH gun shop owner gifts Trump semi-a...   \n",
       "1  RT @CtrlSec: Targeted #ISIS accounts https://t...   \n",
       "2  16-year-old environmental activist Greta Thunb...   \n",
       "3  Thank God for @repdottieb4mo  Under her watch,...   \n",
       "4  The Rise of Purpose Education: A Recipe for Fu...   \n",
       "\n",
       "                                      cleaned_tweets  \\\n",
       "0  nh gun shop owner gifts trump semi-automatic r...   \n",
       "1                                 targeted  accounts   \n",
       "2  16-year-old environmental activist greta thunb...   \n",
       "3  thank god for   under her watch,  110 remains ...   \n",
       "4  the rise of purpose education: a recipe for fu...   \n",
       "\n",
       "                                    tokenized_tweets  \\\n",
       "0  [nh, gun, shop, owner, gifts, trump, semi-auto...   \n",
       "1                               [targeted, accounts]   \n",
       "2  [16-year-old, environmental, activist, greta, ...   \n",
       "3  [thank, god, watch, 110, remains, safe, secure...   \n",
       "4  [rise, purpose, education, recipe, fulfillment...   \n",
       "\n",
       "                                               dummy  \n",
       "0  nh gun shop owner gifts trump semi-automatic r...  \n",
       "1                                  targeted accounts  \n",
       "2  16-year-old environmental activist greta thunb...  \n",
       "3  thank god watch 110 remains safe secure leftis...  \n",
       "4  rise purpose education recipe fulfillment snow...  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() # checking results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stems and Lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import stemmers and lemmatizers\n",
    "\n",
    "from nltk.stem import LancasterStemmer, SnowballStemmer, RegexpStemmer, WordNetLemmatizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiating\n",
    "\n",
    "snowball = SnowballStemmer('english')\n",
    "lancaster = LancasterStemmer() #more aggressive\n",
    "regex_stemmer = RegexpStemmer('ing$|s$|e$|able$', min=4)\n",
    "lemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to get stems and lemmas\n",
    "\n",
    "def stem_words(document,stemmer):\n",
    "    # tokenize the text\n",
    "    toks = word_tokenize(document)\n",
    "    wrd_list = []\n",
    "    # go through the tokens\n",
    "    for word in toks:\n",
    "        # stem the tokens\n",
    "        wrd_list.append(stemmer.stem(word))\n",
    "    # return them\n",
    "    return \" \".join(wrd_list)\n",
    "\n",
    "\n",
    "def lem_words(document,lemmer):\n",
    "    toks = word_tokenize(document)\n",
    "    wrd_list = []\n",
    "    for word in toks:\n",
    "        wrd_list.append(lemmer.lemmatize(word))\n",
    "    return \" \".join(wrd_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['something',\n",
       " 'sticking',\n",
       " 'definitely',\n",
       " 'bothering',\n",
       " 'narrative',\n",
       " 'liberal',\n",
       " '2018',\n",
       " 'basically',\n",
       " 'moderates',\n",
       " 'winning',\n",
       " 'course',\n",
       " 'decision',\n",
       " 'sexy',\n",
       " 'storyline',\n",
       " 'think',\n",
       " 'votes',\n",
       " 'count']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokenized_tweets'][10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### combine tokens into a string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing a randomy dummy row to see how each stemmer/lemmer performs\n",
    "dummy = ' '.join(df['tokenized_tweets'][10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'someth stick definit bother narrat liber 2018 basic moder win cours decis sexi storylin think vote count'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_words(dummy, snowball)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'someth stick definit both nar lib 2018 bas mod win cours decid sexy storylin think vot count'"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_words(dummy, lancaster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'someth stick definitely bother narrativ liberal 2018 basically moderate winn cours decision sexy storylin think vote count'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_words(dummy, regex_stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'something sticking definitely bothering narrative liberal 2018 basically moderate winning course decision sexy storyline think vote count'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lem_words(dummy, lemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just testing stuff out now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'friend'"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma.lemmatize('friends')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['something',\n",
       " 'sticking',\n",
       " 'definitely',\n",
       " 'bothering',\n",
       " 'narrative',\n",
       " 'liberal',\n",
       " '2018',\n",
       " 'basically',\n",
       " 'moderates',\n",
       " 'winning',\n",
       " 'course',\n",
       " 'decision',\n",
       " 'sexy',\n",
       " 'storyline',\n",
       " 'think',\n",
       " 'votes',\n",
       " 'count']"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokenized_tweets'][10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
